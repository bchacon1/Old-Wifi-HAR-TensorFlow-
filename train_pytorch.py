import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from sklearn.model_selection import KFold
import numpy as np
import matplotlib.pyplot as plt
import os
import sklearn.metrics as sk_metrics
import pandas as pd
import sys # For clean exit

# --- Import your model and dataset classes and parameters from pytorch_model.py ---
# Make sure pytorch_model.py contains WifiHARLSTM, WifiActivityDataset,
# and the global parameters like n_input, n_hidden, n_classes, window_size, threshold
from pytorch_model import (
    WifiHARLSTM,
    WifiActivityDataset,
    n_input,
    n_hidden,
    n_classes,
    window_size,
    raw_window_size,
    threshold,
)

# When generating the CSV files via `cross_vali_data_convert_merge.py`, each
# sequence contains `raw_window_size` samples.  During training we downsample
# to `window_size` timesteps to match the TensorFlow pipeline.

# --- CONFIGURABLE PARAMETERS ---
learning_rate = 0.0001
training_iters = 2000  # number of minibatch updates per fold
batch_size = 200
display_step = 100 # How often to print training progress

# --- Data Loading Options ---
# Set to True to load from pre-saved .npy files (much faster after first run)
# Set to False to re-read all CSVs (slow, only needed if CSVs changed or .npy not created)
LOAD_FROM_NPY = True

# Set to True to save the combined data as .npy files after loading from CSVs
# (Only applicable if LOAD_FROM_NPY is False and CSVs are being read)
SAVE_TO_NPY_AFTER_CSV_LOAD = True

# --- Subset for Quick Testing ---
# Set to a float (e.g., 0.1 for 10%) to use only a fraction of the data for quick runs.
# Set to None or 1.0 to use the full dataset.
DATA_SUBSET_FRACTION = None # Or 0.1 for 10%

# --- Checkpointing Options ---
RESUME_FROM_CHECKPOINT = True # Attempt to resume if a checkpoint exists
CHECKPOINT_SAVE_FREQUENCY = 50 # Save a checkpoint every N epochs

# --- Output Folder ---
OUTPUT_FOLDER_PATTERN = "PyTorch_LR{0}_BATCHSIZE{1}_NHIDDEN{2}/"
output_folder = OUTPUT_FOLDER_PATTERN.format(learning_rate, batch_size, n_hidden)
if not os.path.exists(output_folder):
    os.makedirs(output_folder)

# --- Device Configuration ---
# Automatically select CUDA (NVIDIA GPU), MPS (Apple Silicon GPU), or CPU
device = torch.device("cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu")
print(f"Using device: {device}")


# --- STEP 1: Load ALL processed data files (generated by cross_vali_data_convert_merge.py) ---
# This phase can be very slow if loading from CSVs, but fast if loading from .npy
all_features_npy_path = os.path.join(output_folder, "all_features_full.npy")
all_labels_npy_path = os.path.join(output_folder, "all_labels_full.npy")

all_features_full = None
all_labels_full = None

if LOAD_FROM_NPY and os.path.exists(all_features_npy_path) and os.path.exists(all_labels_npy_path):
    print(f"Loading data from pre-saved .npy files: {all_features_npy_path}, {all_labels_npy_path}")
    all_features_full = np.load(all_features_npy_path)
    all_labels_full = np.load(all_labels_npy_path)

    # Ensure shapes match the TensorFlow pipeline expectations
    if all_features_full.shape[1] == raw_window_size:
        all_features_full = all_features_full[:, ::2, :]
    if all_labels_full.shape[1] == 8:
        all_labels_full = all_labels_full[:, 1:]
    print("Data loaded from .npy files successfully.")
else:
    print("Loading data from CSVs (this may take a long time)...")
    activity_labels = ["bed", "fall", "pickup", "run", "sitdown", "standup", "walk"]
    input_files_dir = "./input_files/"

    all_features_list_csv = []
    all_labels_list_csv = []

    for label in activity_labels:
        # Files are saved with the original sequence length (`raw_window_size`)
        # as part of their filename.
        xx_file_path = os.path.join(
            input_files_dir, f"xx_{raw_window_size}_{threshold}_{label}.csv"
        )
        yy_file_path = os.path.join(
            input_files_dir, f"yy_{raw_window_size}_{threshold}_{label}.csv"
        )

        if not os.path.exists(xx_file_path) or not os.path.exists(yy_file_path):
            raise FileNotFoundError(f"Missing data files for activity '{label}'. "
                                    f"Please ensure 'cross_vali_data_convert_merge.py' ran successfully and generated "
                                    f"{xx_file_path} and {yy_file_path}.")

        # Load data using pandas for convenience
        print(f"   Reading CSVs for activity: {label}...")
        features_csv = np.array(pd.read_csv(xx_file_path, header=None)).astype(np.float32)
        labels_csv = np.array(pd.read_csv(yy_file_path, header=None)).astype(np.float32)
        # Drop the "NoActivity" column to match the 7-class setup
        labels_csv = labels_csv[:, 1:]

        # CSVs were generated with `raw_window_size` timesteps.  In the original
        # TensorFlow pipeline each sequence is then downsampled to 500
        # timesteps.  We reproduce the same procedure here.
        features_csv = features_csv.reshape(-1, raw_window_size, n_input)
        features_csv = features_csv[:, ::2, :]

        all_features_list_csv.append(features_csv)
        all_labels_list_csv.append(labels_csv)

    all_features_full = np.concatenate(all_features_list_csv, axis=0)
    all_labels_full = np.concatenate(all_labels_list_csv, axis=0)
    print("Data loaded from CSVs and concatenated successfully.")

    if SAVE_TO_NPY_AFTER_CSV_LOAD:
        print(f"Saving combined data to .npy files for faster loading next time: {output_folder}")
        np.save(all_features_npy_path, all_features_full)
        np.save(all_labels_npy_path, all_labels_full)
        print(".npy files saved.")

# --- Apply Data Subset if specified ---
if DATA_SUBSET_FRACTION is not None and DATA_SUBSET_FRACTION < 1.0:
    print(f"Using a subset of the data: {DATA_SUBSET_FRACTION * 100:.1f}%")
    num_samples_to_use = int(len(all_features_full) * DATA_SUBSET_FRACTION)
    
    # Randomly select indices for the subset
    np.random.seed(42) # For reproducibility of subset
    subset_indices = np.random.choice(len(all_features_full), num_samples_to_use, replace=False)
    
    all_features_full = all_features_full[subset_indices]
    all_labels_full = all_labels_full[subset_indices]

print(f"Total Data for Training: Features shape {all_features_full.shape}, Labels shape {all_labels_full.shape}")


# --- STEP 2: K-Fold Cross-Validation Loop ---
num_folds = 5
kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)

cv_accuracies = []
confusion_matrix_sum = np.zeros((n_classes, n_classes), dtype=int)

print("Starting K-Fold Cross-Validation...")

try: # Wrap the main training loop in a try-except for graceful interruption
    for fold_idx, (train_index, val_index) in enumerate(kf.split(all_features_full, all_labels_full)):
        print(f"\n--- Starting Fold {fold_idx + 1}/{num_folds} ---")

        # Split data into training and validation sets for the current fold
        train_features, val_features = all_features_full[train_index], all_features_full[val_index]
        train_labels, val_labels = all_labels_full[train_index], all_labels_full[val_index]

        # Create PyTorch Dataset objects from the NumPy arrays
        train_dataset = WifiActivityDataset(features=train_features, labels=train_labels)
        val_dataset = WifiActivityDataset(features=val_features, labels=val_labels)

        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)
        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)

        steps_per_epoch = len(train_loader)
        training_epochs = int(np.ceil(training_iters / steps_per_epoch))

        # --- Model, Loss, Optimizer ---
        model = WifiHARLSTM(n_input, n_hidden, n_classes).to(device)
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=learning_rate)

        # --- Training and Validation Metrics for this fold ---
        train_losses = []
        val_losses = []
        train_accuracies = []
        val_accuracies = []

        # --- Resume from Checkpoint ---
        start_epoch = 0
        if RESUME_FROM_CHECKPOINT:
            # Logic to find the latest checkpoint for the current fold
            latest_checkpoint_file = None
            max_epoch_found = -1
            for fname in os.listdir(output_folder):
                if fname.startswith(f"checkpoint_fold{fold_idx + 1}_epoch") and fname.endswith(".pth"):
                    try:
                        epoch_num = int(fname.split('_epoch')[1].split('.pth')[0])
                        if epoch_num > max_epoch_found:
                            max_epoch_found = epoch_num
                            latest_checkpoint_file = os.path.join(output_folder, fname)
                    except ValueError:
                        continue # Skip files not matching expected pattern
            
            if latest_checkpoint_file and os.path.exists(latest_checkpoint_file):
                print(f"    Resuming training for Fold {fold_idx + 1} from checkpoint: {latest_checkpoint_file}")
                checkpoint = torch.load(latest_checkpoint_file, map_location=device) # Map to correct device
                try:
                    model.load_state_dict(checkpoint['model_state_dict'])
                except RuntimeError as e:
                    print(f"      Warning loading state_dict: {e}\n"
                          f"      Attempting to load with strict=False so training can resume.")
                    model.load_state_dict(checkpoint['model_state_dict'], strict=False)
                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
                start_epoch = checkpoint['epoch']
                
                # Load historical data for plotting, if available in checkpoint
                if 'train_loss_history' in checkpoint:
                    train_losses = checkpoint['train_loss_history']
                if 'val_acc_history' in checkpoint:
                    val_accuracies = checkpoint['val_acc_history']
                if 'train_acc_history' in checkpoint: # Added this
                    train_accuracies = checkpoint['train_acc_history']
                if 'val_loss_history' in checkpoint: # Added this
                    val_losses = checkpoint['val_loss_history']

                print(f"    Loaded model from epoch {start_epoch}. Resuming training...")
            else:
                print(f"    No checkpoint found for Fold {fold_idx + 1}. Starting training from epoch 0.")

        # Check if fold is already completed
        if start_epoch * steps_per_epoch >= training_iters:
            print(f"    Fold {fold_idx + 1} already completed all {training_iters} iterations. Skipping training loop for this fold.")
            # If skipping, we might still want to add the last known accuracy to cv_accuracies if available.
            # For simplicity, we'll let the final calculation pick it up if it's there.
            # No new validation run for confusion matrix if training is skipped to avoid redundant computation,
            # assuming the checkpoint state reflects the final performance.
            all_val_preds_fold = [] # Ensure these are empty if loop is skipped
            all_val_true_fold = []
            if val_accuracies: # If val_accuracies was loaded from checkpoint and is not empty
                cv_accuracies.append(val_accuracies[-1]) # Use the last recorded validation accuracy
            else:
                # If no val_accuracies were loaded, or it was empty, we can't add to cv_accuracies.
                # This case should ideally not happen if a fold completed.
                pass
        else:  # Only run training loop if not already completed
            global_step = start_epoch * steps_per_epoch
            for epoch in range(start_epoch, training_epochs):
                # --- Training Phase ---
                model.train()
                running_loss = 0.0
                correct_train = 0
                total_train = 0

                for i, (inputs, labels_onehot) in enumerate(train_loader):
                    inputs, labels_onehot = inputs.to(device), labels_onehot.to(device)
                    labels_int = torch.argmax(labels_onehot, dim=1).long()
                    
                    optimizer.zero_grad()
                    outputs = model(inputs)
                    
                    loss = criterion(outputs, labels_int)
                    loss.backward()
                    optimizer.step()
                    global_step += 1
                    if global_step >= training_iters:
                        break

                    running_loss += loss.item() * inputs.size(0)
                    
                    _, predicted = torch.max(outputs.data, 1)
                    total_train += labels_int.size(0)
                    correct_train += (predicted == labels_int).sum().item()

                epoch_train_loss = running_loss / total_train if total_train > 0 else 0
                epoch_train_accuracy = correct_train / total_train if total_train > 0 else 0
                train_losses.append(epoch_train_loss)
                train_accuracies.append(epoch_train_accuracy)

                # --- Validation Phase ---
                model.eval()
                val_running_loss = 0.0
                correct_val = 0
                total_val = 0
                all_val_preds_fold = []
                all_val_true_fold = []

                with torch.no_grad():
                    for inputs, labels_onehot in val_loader:
                        inputs, labels_onehot = inputs.to(device), labels_onehot.to(device)
                        labels_int = torch.argmax(labels_onehot, dim=1).long()
                        
                        outputs = model(inputs)
                        loss = criterion(outputs, labels_int)
                        val_running_loss += loss.item() * inputs.size(0)

                        _, predicted = torch.max(outputs.data, 1)
                        total_val += labels_int.size(0)
                        correct_val += (predicted == labels_int).sum().item()

                        all_val_preds_fold.extend(predicted.cpu().numpy())
                        all_val_true_fold.extend(labels_int.cpu().numpy())

                epoch_val_loss = val_running_loss / total_val if total_val > 0 else 0
                epoch_val_accuracy = correct_val / total_val if total_val > 0 else 0
                val_losses.append(epoch_val_loss)
                val_accuracies.append(epoch_val_accuracy)

                # --- Display Progress ---
                if (epoch + 1) % display_step == 0 or global_step >= training_iters:
                    print(f"Epoch [{epoch + 1}/{training_epochs}], "
                          f"Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_accuracy:.4f}, "
                          f"Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_accuracy:.4f}")

                # --- Checkpoint Saving ---
                if (epoch + 1) % CHECKPOINT_SAVE_FREQUENCY == 0 or global_step >= training_iters:
                    checkpoint_path = os.path.join(output_folder, f"checkpoint_fold{fold_idx + 1}_epoch{epoch + 1}.pth")
                    torch.save({
                        'epoch': epoch + 1,
                        'model_state_dict': model.state_dict(),
                        'optimizer_state_dict': optimizer.state_dict(),
                        'train_loss_history': train_losses, # Save history for plotting continuity
                        'val_loss_history': val_losses,     # Save history for plotting continuity
                        'train_acc_history': train_accuracies, # Save history for plotting continuity
                        'val_acc_history': val_accuracies, # Save history for plotting continuity
                    }, checkpoint_path)
                    print(f"    Checkpoint saved to {checkpoint_path}")

                if global_step >= training_iters:
                    break

            # Append final validation accuracy for this fold if training occurred
            cv_accuracies.append(epoch_val_accuracy)


        # --- End of Fold ---
        print(f"Fold {fold_idx + 1} Training Finished!")
        
        # Save Accuracy curve for this fold (only if training data was generated)
        if len(train_accuracies) > 0 and len(val_accuracies) > 0:
            plt.figure(figsize=(10, 5))
            plt.plot(train_accuracies, label="Train Accuracy")
            plt.plot(val_accuracies, label="Validation Accuracy")
            plt.xlabel("Epoch")
            plt.ylabel("Accuracy")
            plt.legend()
            plt.ylim([0, 1])
            plt.title(f"Accuracy Curve - Fold {fold_idx + 1}")
            plt.savefig(os.path.join(output_folder, f"Accuracy_Fold{fold_idx + 1}.png"), dpi=150)
            plt.close()
        else:
            print(f"    No training accuracy history to plot for Fold {fold_idx + 1} (possibly skipped training loop).")

        # Save Loss curve for this fold (only if training data was generated)
        if len(train_losses) > 0 and len(val_losses) > 0:
            plt.figure(figsize=(10, 5))
            plt.plot(train_losses, label="Train Loss")
            plt.plot(val_losses, label="Validation Loss")
            plt.xlabel("Epoch")
            plt.ylabel("Loss")
            plt.legend()
            plt.ylim([0, 2])
            plt.title(f"Loss Curve - Fold {fold_idx + 1}")
            plt.savefig(os.path.join(output_folder, f"Loss_Fold{fold_idx + 1}.png"), dpi=150)
            plt.close()
        else:
            print(f"    No training loss history to plot for Fold {fold_idx + 1} (possibly skipped training loop).")

        # Calculate and accumulate confusion matrix for this fold
        # Only if validation data was processed (i.e., training loop was not skipped)
        if len(all_val_true_fold) > 0: # all_val_true_fold is populated inside the validation loop
            conf_matrix_fold = sk_metrics.confusion_matrix(all_val_true_fold, all_val_preds_fold, labels=range(n_classes))
            confusion_matrix_sum += conf_matrix_fold
            print(f"Confusion Matrix for Fold {fold_idx + 1}:\n{conf_matrix_fold}")
        else:
            print(f"    No validation data processed for confusion matrix in Fold {fold_idx + 1} (possibly skipped training loop).")


    print("\n--- Cross-Validation Finished! ---")
    print(f"Average Cross-Validation Accuracy: {np.mean(cv_accuracies):.4f} +/- {np.std(cv_accuracies):.4f}")
    print("Total Confusion Matrix (summed across all folds):\n", confusion_matrix_sum)

    # Save overall confusion matrix
    np.save(os.path.join(output_folder, "total_confusion_matrix.npy"), confusion_matrix_sum)

except KeyboardInterrupt:
    print("\nTraining interrupted by user (Ctrl+C). Exiting gracefully.")
    sys.exit(0) # Exit the script cleanly